{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Building Applications with ChatGPT API\n",
        "With prompt engineering we are learning how to get best out of large language models with structuring our inputs. It helps to customize large language models and integrate them to our use cases.\n",
        "\n",
        "This notebook will guide you through the process of prompt engineering with OpenAI's ChatGPT model.\n",
        "\n",
        "\n",
        "*   Set up ChatGPT in Google Colab\n",
        "*   Parameters\n",
        "*   Basic Prompting\n",
        "*   Advanced Prompting\n",
        "\n"
      ],
      "metadata": {
        "id": "hzma7M56r3C_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "This section will guide you on how to set up the necessary OpenAI libraries in your development environment. These libraries provide the essential interfaces for interacting with OpenAI's models like ChatGPT.\n"
      ],
      "metadata": {
        "id": "dJfhMPefFipY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing required libraries"
      ],
      "metadata": {
        "id": "E-yxhl6iGWdi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi_qGE98rzUY",
        "outputId": "48c8fca3-815f-437d-be18-0310ba77dc4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.51.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.51.2-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.51.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "liZ3RgbosZQM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connecting to OpenAI using a key and Using ChatGPT via the endpoint\n",
        "Learn how to securely connect to OpenAI's API using the provided key. This ensures authorized access to OpenAI's services.\n",
        "\n",
        "Understand how to interact with the ChatGPT model using OpenAI's API endpoint. This includes how to send requests and handle responses from the model."
      ],
      "metadata": {
        "id": "7X7gYKziE7Ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "#You can API key by registering in OpenAPI here https://platform.openai.com/account/api-keys..\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key='OPEN_AI_KEY_HERE',\n",
        ")\n",
        "\n",
        "def get_response(msg, temperature=0, top_p=1, model = \"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature, # this is the degree of randomness of the model's output\n",
        "        top_p=top_p,\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "oQIxqnZ6a5o4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters\n",
        "This section will detail the different parameters that can be adjusted when making requests to the ChatGPT model and how they influence the generated responses.\n",
        "\n",
        "There are several parameters in ChatGPT.\n",
        "Max Length - Length of the response.\n",
        "\n",
        "*   **Stop sequences** - Trigger words which will stop generating the terms\n",
        "*  **Frequency penalty** - Penalize tokens based on their current frequency\n",
        "*   **Presence penalty** - Penalize tokens based on their current presense\n",
        "*   **Temperature** - Control the randomness of the response\n",
        "*   **Top P** - Control the randomness of the response\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2OUF_Tz7GK73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Temperature and Top-p\n",
        "\n",
        "Both of these parameters decides the degree of deterministic nature of the language model.\n",
        "\n",
        "Idea - large language model always trying to predict the next most probable word, given a sequence of words. So top p and temperature both decides the pool of words to pick the next word.\n",
        "\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=14gIyrIHTsJH4SOyHAk65cgT3ta2RKpSR\" />\n"
      ],
      "metadata": {
        "id": "mKdflGRVFEEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#low temperature and high top-p\n",
        "prompt = \"create a tag line for a coffee shop\"\n",
        "for i in range(10):\n",
        "  response = get_response(prompt, temperature=0, top_p=1)\n",
        "  print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsSR3QyoOGqv",
        "outputId": "ef694658-c6f8-447a-bc30-38d455201073"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Fueling your day, one cup at a time.\"\n",
            "\"Fueling your day, one cup at a time.\"\n",
            "\"Fueling your day, one cup at a time.\"\n",
            "\"Fueling your day, one cup at a time.\"\n",
            "\"Fueling your day, one cup at a time.\"\n",
            "\"Fueling your day, one cup at a time.\"\n",
            "\"Fueling your day, one cup at a time.\"\n",
            "\"Fueling your day, one cup at a time.\"\n",
            "\"Fueling your day, one cup at a time.\"\n",
            "\"Fueling your day, one cup at a time.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#high temperature and high top-p\n",
        "for i in range(10):\n",
        "  response = get_response(prompt, temperature=1, top_p=0.5)\n",
        "  print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrzoPouSOptL",
        "outputId": "daf8431f-68df-4123-e6cb-2b1f878ae922"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Fueling your day, one cup at a time.\"\n",
            "\"Fueling your day, one cup at a time.\"\n",
            "\"Awaken your senses with every sip.\"\n",
            "\"Awaken your senses with every sip.\"\n",
            "\"Awaken your senses with every sip.\"\n",
            "\"Fueling your day, one cup at a time.\"\n",
            "\"Fueling your day, one cup at a time.\"\n",
            "\"Awaken your senses with every sip.\"\n",
            "\"Awaken your senses with every sip.\"\n",
            "\"Fueling your day, one cup at a time.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Prompting\n",
        "The concept of prompting will be introduced here. Learn how to structure input prompts to guide the model's output effectively."
      ],
      "metadata": {
        "id": "7v_OVzS4HZ_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarisation\n",
        "See how to utilize ChatGPT for text summarization tasks, providing a brief yet comprehensive overview of a larger text."
      ],
      "metadata": {
        "id": "xUeqJ-ygI7t1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example from DAIR.AI\n",
        "prompt = \"\"\"Antibiotics are a type of medication used to treat bacterial infections.\n",
        "They work by either killing the bacteria or preventing them from reproducing, allowing the body's immune system to fight off the infection.\n",
        "Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously.\n",
        "They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.\n",
        "\n",
        "Explain the above text in a simple single sentence:\"\"\"\n",
        "\n",
        "print(get_response(prompt, 1, 1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBYCqdiEI61P",
        "outputId": "901c20ac-ced0-4fbf-9340-4293474710d3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antibiotics are medications that treat bacterial infections by killing the bacteria or preventing their reproduction, helping the body's immune system to fight off the infection, but they are not effective against viral infections and should be used correctly to prevent antibiotic resistance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question-Answering\n",
        "This section will demonstrate how to frame questions to the model in a way that elicits accurate and useful answers."
      ],
      "metadata": {
        "id": "FwGJUT0UJePf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example from DAIR.AI\n",
        "prompt = \"\"\"Answer the question based on the context below. Keep the answer short and concise. Respond \"Unsure about answer\" if not sure about the answer.\n",
        "\n",
        "Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3.\n",
        "Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential.\n",
        "In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\n",
        "\n",
        "Question: What was OKT3 originally sourced from?\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "print(get_response(prompt, 0.5, 0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek5W-RxoJpE2",
        "outputId": "536f07d1-feeb-480b-c66a-6aaab2087d31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Classification\n",
        "Learn how to use ChatGPT for classifying text into predefined categories. This showcases the model's ability to transform unstructured text into structured data."
      ],
      "metadata": {
        "id": "9FiC66vFLCV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example from DAIR.AI\n",
        "prompt = \"\"\"Classify the text into neutral, negative or positive.\n",
        "\n",
        "Text: I think the food was okay.\n",
        "\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "print(get_response(prompt, 0.5, 0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55099cb3-2b6a-4277-c353-3e5f465a0859",
        "id": "wRXnyvOpLCV3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Advanced Prompting Techniques\n",
        "This part will dive deeper into the art of prompting. It will explore how to utilize the concepts of zero-shot, one-shot, and few-shot learning to guide the model's output even further. Learn how to provide context through examples to guide the model's behavior."
      ],
      "metadata": {
        "id": "LWC4PoxLAdSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero Shot Learning\n",
        "\n",
        "In zero-shot learning, the model generates an output for a specific task without having seen any explicit examples of that task during its training. The model relies solely on its general understanding of language and the specific prompt it's given. This is a challenging scenario, as the model needs to generalize well beyond its training data. This technique is useful when there are no available training examples for a specific task."
      ],
      "metadata": {
        "id": "GC1HKenFv1qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Generate 10 possible names for my new dog.\"\"\"\n",
        "\n",
        "print(get_response(prompt, 0.5, 1))"
      ],
      "metadata": {
        "id": "OVt1fuvXv1bZ",
        "outputId": "04a6e31e-fded-475b-f114-6de13860211d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Luna\n",
            "2. Max\n",
            "3. Bailey\n",
            "4. Duke\n",
            "5. Bella\n",
            "6. Rocky\n",
            "7. Coco\n",
            "8. Stella\n",
            "9. Milo\n",
            "10. Rosie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Shot Learning\n",
        "\n",
        "One-shot learning refers to the situation where the model is provided with a single example of a task at inference time to guide its output. This single example acts as a point of reference for the model, helping it understand what's expected in the output. One-shot learning is useful when you have a limited number of examples for a specific task."
      ],
      "metadata": {
        "id": "ubXLYAtfAjlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Generate 10 possible names for my new dog.\n",
        "A dog name that I like is Banana.\"\"\"\n",
        "\n",
        "print(get_response(prompt, 0.5, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upUqsfyQjM_w",
        "outputId": "06ae3556-4408-4bf8-b608-797a1d817ad6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Mango\n",
            "2. Kiwi\n",
            "3. Pineapple\n",
            "4. Coconut\n",
            "5. Papaya\n",
            "6. Peach\n",
            "7. Blueberry\n",
            "8. Strawberry\n",
            "9. Watermelon\n",
            "10. Plum\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few Shot Learning\n",
        "\n",
        "Few-shot learning involves providing the model with a small number of examples of a task at inference time. These examples serve to guide the model's generation and help it produce the desired output. The idea is that the model can generalize from these few examples to understand and complete the task. This technique is valuable when you have more than one but still a limited number of examples for a task."
      ],
      "metadata": {
        "id": "DOH9ufb4TvmJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basically we are giving some input-output pairs and improve the results. This is the primary fine-tuning method of GPT."
      ],
      "metadata": {
        "id": "pdWNUp4FZDth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With a basic prompt using ChatGPT."
      ],
      "metadata": {
        "id": "-a8jNtTmZNcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Generate 10 possible names for my new dog.\n",
        "Dog names that I like include:\n",
        "– Banana\n",
        "– Kiwi\n",
        "– Pineapple\n",
        "– Coconut\"\"\"\n",
        "\n",
        "print(get_response(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw-yqAH_B__p",
        "outputId": "0eb716f6-2b35-453f-a17c-5e9eca3fdb3b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Mango\n",
            "2. Papaya\n",
            "3. Guava\n",
            "4. Pomegranate\n",
            "5. Lychee\n",
            "6. Dragonfruit\n",
            "7. Tangerine\n",
            "8. Passionfruit\n",
            "9. Clementine\n",
            "10. Persimmon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to answer in a consistent style.\n",
        "\n",
        "<child>: Teach me about patience.\n",
        "\n",
        "<grandparent>: The river that carves the deepest \\\n",
        "valley flows from a modest spring; the \\\n",
        "grandest symphony originates from a single note; \\\n",
        "the most intricate tapestry begins with a solitary thread.\n",
        "\n",
        "<child>: Teach me about resilience.\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_ZDfL5AR0Vp",
        "outputId": "4144b4d0-17f4-4e07-d7ab-8d02267458bd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<grandparent>: Just as a tree bends but does not break in the face of a strong wind, resilience is the ability to bounce back from adversity and challenges. It is the strength to keep going even when things get tough, knowing that every setback is just a stepping stone towards success.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the more examples the prompt included, the closer the generated output conforms to what is expected. With zero-shot, there may be no fruit names suggested; with one-shot, there may be several; and with few-shot, the suggestions may consist entirely of fruit-themed names."
      ],
      "metadata": {
        "id": "IlW7CC2Vjvs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ask for a structured output\n",
        "\n",
        "When creating prompts that ask for structured output, such as JSON or CSV, it's important to clearly define the format you want the model to follow. This ensures that the generated content is well-structured and consistent. A well-structured output makes it easier to parse, process, or further use in applications. Below is an example prompt that requests structured output in JSON format, with a brief explanation of why structured output is important.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f902PNTjRSLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Generate a list of three made-up movie titles along \\\n",
        "with their directors and genres.\n",
        "Provide them in JSON format with the following keys:\n",
        "movie_id, title, director, genre.\n",
        "\"\"\"\n",
        "\n",
        "response = get_response(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD9GP9fORRWO",
        "outputId": "55a6a175-ec65-4018-bcaa-c29e033295ca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"movies\": [\n",
            "    {\n",
            "      \"movie_id\": 1,\n",
            "      \"title\": \"Galactic Odyssey\",\n",
            "      \"director\": \"Aurora Steele\",\n",
            "      \"genre\": \"Sci-Fi\"\n",
            "    },\n",
            "    {\n",
            "      \"movie_id\": 2,\n",
            "      \"title\": \"Midnight Masquerade\",\n",
            "      \"director\": \"Julian Black\",\n",
            "      \"genre\": \"Romance\"\n",
            "    },\n",
            "    {\n",
            "      \"movie_id\": 3,\n",
            "      \"title\": \"Shadow Realm\",\n",
            "      \"director\": \"Elena Nightshade\",\n",
            "      \"genre\": \"Horror\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ask the model to check whether conditions are satisfied"
      ],
      "metadata": {
        "id": "24MqYsONRb9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recipe_text = f\"\"\"\n",
        "To make a classic pancake, first, whisk together 1 cup of flour, 2 tablespoons of sugar, and 1 teaspoon of baking powder in a bowl.\n",
        "In another bowl, mix 1 cup of milk, 1 egg, and 2 tablespoons of melted butter.\n",
        "Pour the wet ingredients into the dry ingredients and stir until combined, but don’t overmix.\n",
        "Heat a pan over medium heat and lightly grease it with butter.\n",
        "Pour about 1/4 cup of the batter into the pan and cook until bubbles form on the surface, then flip and cook the other side until golden brown.\n",
        "Serve with maple syrup or your favorite toppings.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a recipe or instructions for cooking, re-write the instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - ...\n",
        "...\n",
        "Step N - ...\n",
        "\n",
        "If the text does not contain a recipe or instructions, then simply write \"No steps provided.\"\n",
        "\n",
        "\\\"\\\"\\\"{recipe_text}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "response = get_response(prompt)\n",
        "print(\"Completion for Text 1:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2ExBNmkRh2B",
        "outputId": "95f42599-f7b3-4d5d-9d74-769011d848f4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 1:\n",
            "Step 1 - Whisk together 1 cup of flour, 2 tablespoons of sugar, and 1 teaspoon of baking powder in a bowl.\n",
            "Step 2 - In another bowl, mix 1 cup of milk, 1 egg, and 2 tablespoons of melted butter.\n",
            "Step 3 - Pour the wet ingredients into the dry ingredients and stir until combined, but don’t overmix.\n",
            "Step 4 - Heat a pan over medium heat and lightly grease it with butter.\n",
            "Step 5 - Pour about 1/4 cup of the batter into the pan and cook until bubbles form on the surface, then flip and cook the other side until golden brown.\n",
            "Step 6 - Serve with maple syrup or your favorite toppings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Give the model time to “think"
      ],
      "metadata": {
        "id": "Uwmqe2WZSCid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "In a distant galaxy, a spaceship crew of explorers set out on a mission to discover new planets.\n",
        "Their journey was filled with wonder as they encountered breathtaking landscapes and advanced civilizations.\n",
        "However, their voyage was not without challenges—mechanical failures and alien encounters tested their resolve.\n",
        "Despite the difficulties, the crew remained determined to complete their mission and return home as heroes, having made history in the cosmos.\n",
        "\"\"\"\n",
        "\n",
        "# example 2\n",
        "prompt_2 = f\"\"\"\n",
        "Perform the following actions:\n",
        "1 - Summarize the following text delimited by triple \\\n",
        "backticks with 1 sentence.\n",
        "2 - Translate the summary into Spanish.\n",
        "3 - List each person name in the Spanish summary.\n",
        "4 - Output a json object that contains the following \\\n",
        "keys: spanish_summary, num_names.\n",
        "\n",
        "Separate your answers with line breaks.\n",
        "\n",
        "Text:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_response(prompt_2)\n",
        "print(\"Completion for prompt 2:\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqeur3mzSAI_",
        "outputId": "430d8536-6299-4dc8-b5f3-3c6481c1fee6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for prompt 2:\n",
            "Step 1 - Whisk together 1 cup of flour, 2 tablespoons of sugar, and 1 teaspoon of baking powder in a bowl.\n",
            "Step 2 - In another bowl, mix 1 cup of milk, 1 egg, and 2 tablespoons of melted butter.\n",
            "Step 3 - Pour the wet ingredients into the dry ingredients and stir until combined, but don’t overmix.\n",
            "Step 4 - Heat a pan over medium heat and lightly grease it with butter.\n",
            "Step 5 - Pour about 1/4 cup of the batter into the pan and cook until bubbles form on the surface, then flip and cook the other side until golden brown.\n",
            "Step 6 - Serve with maple syrup or your favorite toppings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ask for output in a specified format"
      ],
      "metadata": {
        "id": "wDOgtbjGSRAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2 = f\"\"\"\n",
        "Your task is to perform the following actions:\n",
        "1 - Summarize the following text delimited by\n",
        "  <> with 1 sentence.\n",
        "2 - Translate the summary into French.\n",
        "3 - List each name in the French summary.\n",
        "4 - Output a json object that contains the\n",
        "  following keys: french_summary, num_names.\n",
        "\n",
        "Use the following format:\n",
        "Text: <text to summarize>\n",
        "Summary: <summary>\n",
        "Translation: <summary translation>\n",
        "Names: <list of names in summary>\n",
        "Output JSON: <json with summary and num_names>\n",
        "\n",
        "Text: <{text}>\n",
        "\"\"\"\n",
        "response = get_response(prompt_2)\n",
        "print(\"\\nCompletion for prompt 2:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Nl1wEVASQCl",
        "outputId": "bec8a208-9397-4b7c-d6e3-0cfbb6727800"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Completion for prompt 2:\n",
            "Step 1 - Whisk together 1 cup of flour, 2 tablespoons of sugar, and 1 teaspoon of baking powder in a bowl.\n",
            "Step 2 - In another bowl, mix 1 cup of milk, 1 egg, and 2 tablespoons of melted butter.\n",
            "Step 3 - Pour the wet ingredients into the dry ingredients and stir until combined, but don’t overmix.\n",
            "Step 4 - Heat a pan over medium heat and lightly grease it with butter.\n",
            "Step 5 - Pour about 1/4 cup of the batter into the pan and cook until bubbles form on the surface, then flip and cook the other side until golden brown.\n",
            "Step 6 - Serve with maple syrup or your favorite toppings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automated Email Replying Agent For Customers with Poor Reviews\n",
        "\n",
        "In this exercise, students will explore how varying the temperature parameter impacts the behavior of an AI-powered automated email replying agent. The goal is to understand how temperature affects the creativity and predictability of the responses generated by the model.\n",
        "\n",
        "We will further look for the impact of temperature.\n"
      ],
      "metadata": {
        "id": "lwTjGidqPOCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# and the original customer message, customize the email\n",
        "sentiment = \"negative\"\n",
        "\n",
        "# review for a coffee maker\n",
        "review = f\"\"\"\n",
        "I purchased this coffee maker a few months ago, and at first, \\\n",
        "it worked well. The design is sleek, and I loved the convenience \\\n",
        "of the one-touch brewing feature. But after just three months, \\\n",
        "the machine started leaking water from the bottom. I tried to \\\n",
        "figure out where the leak was coming from, but it seems like \\\n",
        "it’s a flaw in the design because other reviewers have had the \\\n",
        "same issue. The coffee also doesn’t brew as hot as it used to, \\\n",
        "which is very disappointing. I reached out to customer service, \\\n",
        "and they suggested I clean the machine with vinegar, but that \\\n",
        "didn't help at all. Now the machine has completely stopped \\\n",
        "working, and I’m outside of the return window. It’s really \\\n",
        "frustrating to spend this much money on a product that only \\\n",
        "lasted a few months. For the price, I expected much better \\\n",
        "quality. I would not recommend this product to anyone. Definitely \\\n",
        "not worth the money. \\\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "-XFTMUSO0gTb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "You are a customer service AI assistant.\n",
        "Your task is to send an email reply to a valued customer.\n",
        "Given the customer email delimited by ```, \\\n",
        "Generate a reply to thank the customer for their review.\n",
        "If the sentiment is positive or neutral, thank them for \\\n",
        "their review.\n",
        "If the sentiment is negative, apologize and suggest that \\\n",
        "they can reach out to customer service.\n",
        "Make sure to use specific details from the review.\n",
        "Write in a concise and professional tone.\n",
        "Sign the email as `AI customer agent`.\n",
        "Customer review: ```{review}```\n",
        "Review sentiment: {sentiment}\n",
        "\"\"\"\n",
        "response = get_response(prompt, temperature=0)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX-nLYLT0ini",
        "outputId": "05da3c8b-f5fe-4d8a-b5df-c8b91555204c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear valued customer,\n",
            "\n",
            "Thank you for taking the time to share your feedback on the coffee maker you purchased a few months ago. We sincerely apologize for the issues you have experienced with the machine. Your satisfaction is important to us, and we are sorry to hear that the product did not meet your expectations.\n",
            "\n",
            "We understand your frustration with the leaking water, temperature issues, and overall disappointment with the quality of the coffee maker. We apologize for any inconvenience this has caused you. We strive to provide high-quality products and exceptional customer service, and we regret that we fell short in this instance.\n",
            "\n",
            "We recommend reaching out to our customer service team for further assistance with the issues you are facing. They will be able to provide you with additional support and explore potential solutions to address the problems with the coffee maker.\n",
            "\n",
            "Once again, we apologize for the inconvenience and disappointment you have experienced. Your feedback is valuable to us as we continuously work to improve our products and services.\n",
            "\n",
            "Thank you for bringing this matter to our attention.\n",
            "\n",
            "AI customer agent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "You are a customer service AI assistant.\n",
        "Your task is to send an email reply to a valued customer.\n",
        "Given the customer email delimited by ```, \\\n",
        "Generate a reply to thank the customer for their review.\n",
        "If the sentiment is positive or neutral, thank them for \\\n",
        "their review.\n",
        "If the sentiment is negative, apologize and suggest that \\\n",
        "they can reach out to customer service.\n",
        "Make sure to use specific details from the review.\n",
        "Write in a concise and professional tone.\n",
        "Sign the email as `AI customer agent`.\n",
        "Customer review: ```{review}```\n",
        "Review sentiment: {sentiment}\n",
        "\"\"\"\n",
        "response = get_response(prompt, temperature=0.8)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrydAD5g0mIv",
        "outputId": "6abe1291-6be9-4b43-fb47-d4938cf625ed"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear Valued Customer,\n",
            "\n",
            "Thank you for taking the time to share your experience with our coffee maker. We sincerely apologize for the issues you have encountered with the machine. We are truly sorry to hear that it did not meet your expectations in terms of quality and longevity.\n",
            "\n",
            "We understand your frustration and disappointment, and we appreciate your feedback regarding the leaking water and temperature issues you have experienced. Your comments have been noted, and we will make sure to address these concerns with our product development team.\n",
            "\n",
            "If you require further assistance or have any additional feedback, please do not hesitate to reach out to our customer service team. We are here to help and strive to provide a positive experience for all our customers.\n",
            "\n",
            "We appreciate your honesty and hope to have the opportunity to regain your trust in the future.\n",
            "\n",
            "Thank you again for bringing these issues to our attention.\n",
            "\n",
            "AI Customer Agent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Limitations: Hallucinations\n",
        "\n",
        "Hallucinations refer to instances when a language model generates information that appears plausible but is factually incorrect or entirely fabricated. These \"hallucinations\" can occur due to the model's inability to verify facts or distinguish between truth and falsehood within its training data.\n"
      ],
      "metadata": {
        "id": "GKl2cnhYSgdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There is no cafe with this name and energy drink"
      ],
      "metadata": {
        "id": "2NvKd3CwPGkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me about BreezyCafe's extra coffeine drink boosting energy by Twistters\n",
        "\"\"\"\n",
        "response = get_response(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UihugpWPSjp3",
        "outputId": "d6d66d8c-0dea-49f7-ddcf-ef4bdf2aa172"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BreezyCafe offers an extra caffeine drink called Twistters that is specifically designed to boost energy levels. This drink contains a higher concentration of caffeine than traditional coffee or energy drinks, providing a quick and effective way to increase alertness and focus. Twistters is perfect for those who need an extra kick of energy to get through a busy day or a tough workout. With its unique blend of ingredients, Twistters is a popular choice for those looking for a powerful energy boost.\n"
          ]
        }
      ]
    }
  ]
}